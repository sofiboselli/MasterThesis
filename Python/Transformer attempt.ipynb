{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "c75c9fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch import Tensor\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Transformer\n",
    "from torch.utils.data import dataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from einops.layers.torch import Rearrange, Reduce\n",
    "from einops import rearrange, reduce, repeat\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import more_itertools\n",
    "import math\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42787c25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = 'mps'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "DEVICE = torch.device(device)\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5b2efc",
   "metadata": {},
   "source": [
    "## DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f437e8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load('sub1.npy')\n",
    "stim1 = np.load('stim.npy')\n",
    "stim2 = np.load('mask.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ed718b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xx = []\n",
    "stimulus = []\n",
    "masker = []\n",
    "for i in range(80):\n",
    "    x = []\n",
    "    for j in range(66):\n",
    "        t = np.array(list(more_itertools.sliced(X[i][j],n=128)))\n",
    "        x.append(t.T)\n",
    "    Xx.append(np.asarray(x).T)\n",
    "    stimulus.append(np.array(list(more_itertools.sliced(stim1[i],n=128))))\n",
    "    masker.append(np.array(list(more_itertools.sliced(stim2[i],n=128))))\n",
    "\n",
    "X = np.array(Xx)\n",
    "stim = np.array(stimulus)\n",
    "mask = np.array(masker)\n",
    "\n",
    "X = X.reshape((80*33,128,66))\n",
    "stim = stim.reshape((80*33,128))\n",
    "mask = mask.reshape((80*33,128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "458ae86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_valid,y_tr,y_val,m,mv = train_test_split(X,stim,mask,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80581f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "trsc = StandardScaler()\n",
    "X_tr = []\n",
    "X_val = []\n",
    "for i in range(len(X_train)):\n",
    "    X_tr.append(np.expand_dims(trsc.fit_transform(X_train[i]),axis=-1).astype(np.float32))\n",
    "\n",
    "for i in range(len(X_valid)):\n",
    "    X_val.append(np.expand_dims(trsc.fit_transform(X_valid[i]),axis=-1).astype(np.float32))\n",
    "\n",
    "X_tr = np.array(X_tr)\n",
    "X_val = np.array(X_val)\n",
    "\n",
    "trst = StandardScaler()\n",
    "y_tr = trst.fit_transform(y_tr.T).astype(np.float32).T\n",
    "y_val = trst.fit_transform(y_val.T).astype(np.float32).T\n",
    "\n",
    "trsm = StandardScaler()\n",
    "m_tr = trsm.fit_transform(m.T).astype(np.float32).T\n",
    "m_val = trsm.fit_transform(mv.T).astype(np.float32).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a20becd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tr = np.expand_dims(y_tr,axis=-1)\n",
    "y_val = np.expand_dims(y_val,axis=-1)\n",
    "m_val = np.expand_dims(m_val,axis=-1)\n",
    "m_tr = np.expand_dims(m_tr,axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "66a83d50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2112, 128, 1)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2feeb59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "stimtr = np.roll(y_tr,1,axis=1)\n",
    "stimval = np.roll(y_val,1,axis=1)\n",
    "stimtr[:,0] = np.mean(X_tr,axis=2)[:,0]\n",
    "stimval[:,0] =  np.mean(X_val,axis=2)[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a7f4b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices(((X_tr,stimtr),y_tr))\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices(((X_val,stimval),y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7a45db9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.batch(4).shuffle(32)\n",
    "train_dataset = train_dataset.prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e0b74800",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_PrefetchDataset element_spec=((TensorSpec(shape=(None, 128, 66, 1), dtype=tf.float32, name=None), TensorSpec(shape=(None, 128, 1), dtype=tf.float32, name=None)), TensorSpec(shape=(None, 128, 1), dtype=tf.float32, name=None))>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c7363ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = val_dataset.batch(4)\n",
    "val_dataset = val_dataset.prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "12930afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PairDataset(Dataset):\n",
    "    def __init__(self, eeg, att):\n",
    "        self.eeg = eeg\n",
    "        self.att = att\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.eeg)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.eeg[idx,:,:,:], self.att[idx,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ff18f653",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = PairDataset(X_tr, y_tr)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=1,\n",
    "                              shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "91cc404a",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = PairDataset(X_val, y_val)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0c8393aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for eeg, att in train_dataloader:  \n",
    "    sample_eeg = eeg    # Reshape them according to your needs.\n",
    "    sample_att = att\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "57b343b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 128, 66, 1])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_eeg.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174d6238",
   "metadata": {},
   "source": [
    "## TRANSFORMER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "d808b738",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self,\n",
    "                 emb_size: int,\n",
    "                 dropout: float,\n",
    "                 maxlen: int = 5000):\n",
    "        super().__init__()\n",
    "        den = torch.exp(- torch.arange(0, emb_size, 2)\n",
    "                        * math.log(10000) / emb_size)\n",
    "        pos = torch.arange(0, maxlen).reshape(maxlen, 1)\n",
    "        pos_embedding = torch.zeros((maxlen, emb_size))\n",
    "        pos_embedding[:, 0::2] = torch.sin(pos * den)\n",
    "        pos_embedding[:, 1::2] = torch.cos(pos * den)\n",
    "        pos_embedding = pos_embedding.unsqueeze(-2)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer('pos_embedding', pos_embedding)\n",
    "        self.emb_size = emb_size\n",
    "\n",
    "    def forward(self, token_embedding: Tensor):\n",
    "#         print(\"token_embedding.shape: \",token_embedding.shape)\n",
    "#         print(\"token_embedding.size(0): \",token_embedding.size(0))\n",
    "#         print(\"elf.pos_embedding[:token_embedding.size(0), :].shape: \",self.pos_embedding[:token_embedding.size(0), :].shape)\n",
    "        return self.dropout(token_embedding * math.sqrt(self.emb_size)\n",
    "                            + self.pos_embedding[:token_embedding.size(0), :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "id": "8454b0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embedding(nn.Module):\n",
    "    def __init__(self, kdim):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 5, (1,16),(1,1),padding=\"same\")\n",
    "        self.gelu = F.gelu\n",
    "        self.norm = nn.BatchNorm2d(5)\n",
    "        self.depthConv = nn.Conv2d(5, kdim, (1,15),padding=\"same\")\n",
    "        self.conv2 = nn.Conv2d(5, 16, (15,1),padding=\"same\")\n",
    "        self.dense = nn.Linear(16,13)\n",
    "        self.conv3 = nn.Conv1d(1, kdim, 2, padding=\"same\")\n",
    "        self.rearrange = Rearrange('b e (h) (w) -> b (h w) e')\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        if len(x.shape) == 4:\n",
    "            x = x.permute(0, 3, 1, 2)\n",
    "            #print(\"INPUT: \", x.shape)\n",
    "            x = self.gelu(self.conv1(x))\n",
    "            #print(\"CONV: \", x.shape)\n",
    "            x = self.norm(x)\n",
    "            #print(\"BATCH: \", x.shape)\n",
    "            x = self.gelu(self.conv2(x))\n",
    "            #print(\"CONV: \", x.shape)\n",
    "            x = self.rearrange(x) #x.permute(0, 2, 3, 1)\n",
    "            #print(\"PERM: \", x.shape)\n",
    "#             x = self.dense(x)\n",
    "#             print(\"DENSE: \", x.shape)\n",
    "        else:\n",
    "            x = x.permute(0, 2, 1)\n",
    "            x = self.gelu(self.conv3(x))\n",
    "            x = x.permute(0, 2, 1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "id": "0be24320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 128, 66, 1])\n",
      "torch.Size([1, 128, 1])\n",
      "torch.Size([1, 8448, 16])\n",
      "torch.Size([1, 128, 16])\n"
     ]
    }
   ],
   "source": [
    "Emb = Embedding(16)\n",
    "for eeg, att in train_dataloader:  \n",
    "    print(eeg.shape)\n",
    "    print(att.shape)\n",
    "    sample_eeg_embedding = Emb(eeg)    # Reshape them according to your needs.\n",
    "    sample_att_embedding = Emb(att)\n",
    "    break\n",
    "\n",
    "print(sample_eeg_embedding.shape)\n",
    "print(sample_att_embedding.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "id": "e21e7333",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchEmbedding(nn.Module):\n",
    "    def __init__(self, emb_size):\n",
    "        # self.patch_size = patch_size\n",
    "        super().__init__()\n",
    "        self.projection = nn.Sequential(\n",
    "            nn.Conv2d(1, 2, (1, 51), (1, 1)),\n",
    "            nn.BatchNorm2d(2),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(2, emb_size, (16, 5), stride=(1, 5)),\n",
    "            Rearrange('b e (h) (w) -> b (h w) e'),\n",
    "        )\n",
    "        self.one = nn.Conv2d(1, 2, (1, 51), (1, 1))\n",
    "        self.two = nn.BatchNorm2d(2)\n",
    "        self.three = nn.LeakyReLU(0.2)\n",
    "        self.four = nn.Conv2d(2, emb_size, (16, 5), stride=(1, 5))\n",
    "        self.five = Rearrange('b e (h) (w) -> b (h w) e')\n",
    "        self.cls_token = nn.Parameter(torch.randn(1, 1, emb_size))\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        x = x.permute(0, 3, 1, 2)\n",
    "        b, _, _, _ = x.shape\n",
    "#         x = self.projection(x)\n",
    "        print(\"INPUT: \", x.shape)\n",
    "        x = self.one(x)\n",
    "        print(\"CONV: \", x.shape)\n",
    "        x = self.two(x)\n",
    "        print(\"BATCH: \", x.shape)\n",
    "        x = self.three(x)\n",
    "        print(\"RELU: \", x.shape)\n",
    "        x = self.four(x)\n",
    "        print(\"CONV: \", x.shape)\n",
    "        x = self.five(x)\n",
    "        print(\"REARRANGE: \", x.shape)\n",
    "        cls_tokens = repeat(self.cls_token, '() n e -> b n e', b=b)\n",
    "\n",
    "        # position\n",
    "        # x += self.positions\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "id": "8b90d80d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 128, 66, 1])\n",
      "INPUT:  torch.Size([1, 1, 128, 66])\n",
      "CONV:  torch.Size([1, 2, 128, 16])\n",
      "BATCH:  torch.Size([1, 2, 128, 16])\n",
      "RELU:  torch.Size([1, 2, 128, 16])\n",
      "CONV:  torch.Size([1, 16, 113, 3])\n",
      "REARRANGE:  torch.Size([1, 339, 16])\n",
      "torch.Size([1, 339, 16])\n"
     ]
    }
   ],
   "source": [
    "Emb = PatchEmbedding(16)\n",
    "for eeg, att in train_dataloader:  \n",
    "    print(eeg.shape)\n",
    "#     print(att.shape)\n",
    "    sample_eeg_embedding = Emb(eeg)    # Reshape them according to your needs.\n",
    "#     sample_att_embedding = Emb(att)\n",
    "    break\n",
    "\n",
    "print(sample_eeg_embedding.shape)\n",
    "# print(sample_att_embedding.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "id": "c9e16759",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEG_Transformer(nn.Module):\n",
    "    def __init__(self,\n",
    "                 num_encoder_layers: int,\n",
    "                 num_decoder_layers: int,\n",
    "                 emb_size: int,\n",
    "#                  emb_size_eeg: int,\n",
    "#                  emb_size_att: int,\n",
    "                 nhead: int,\n",
    "                 dim_feedforward: int = 512,\n",
    "                 dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.transformer = Transformer(d_model=emb_size,\n",
    "                                       nhead=nhead,\n",
    "                                       num_encoder_layers=num_encoder_layers,\n",
    "                                       num_decoder_layers=num_decoder_layers,\n",
    "                                       dim_feedforward=dim_feedforward,\n",
    "                                       dropout=dropout,\n",
    "                                       batch_first=True)\n",
    "\n",
    "        self.emb_size = emb_size\n",
    "        self.embedding = Embedding(emb_size)\n",
    "        self.positional_encoding = PositionalEncoding(emb_size, dropout=dropout)\n",
    "        # Bias to be compatible with embeddings\n",
    "#         self.generator = nn.Linear(emb_size, vocab_size, bias=False)\n",
    "#         self.generator.weight = self.embedding.weight  # Shared weights Sect. 3.4\n",
    "\n",
    "    def forward(self,\n",
    "                src: Tensor,\n",
    "                trg: Tensor):\n",
    "        src_emb = self.positional_encoding(self.embedding(src))\n",
    "        tgt_emb = self.positional_encoding(self.embedding(trg))\n",
    "        print(\"SIZE OF src_emb: \", src_emb.shape)\n",
    "        print(\"SIZE OF tgt_emb: \", tgt_emb.shape)\n",
    "        src_mask, tgt_mask = create_mask(src_emb, tgt_emb)\n",
    "        print(\"SIZE OF src_mask: \", src_mask.shape)\n",
    "        print(\"SIZE OF tgt_mask: \", tgt_mask.shape)\n",
    "        outs = self.transformer(src_emb, tgt_emb, src_mask, tgt_mask, None)\n",
    "        return outs #self.generator(outs)\n",
    "\n",
    "    def encode(self, src: Tensor, src_mask: Tensor):\n",
    "        return self.transformer.encoder(self.positional_encoding(\n",
    "            self.embedding(src)), src_mask)\n",
    "\n",
    "    def decode(self, tgt: Tensor, memory: Tensor, tgt_mask: Tensor):\n",
    "        return self.transformer.decoder(self.positional_encoding(\n",
    "            self.embedding(tgt)), memory,\n",
    "            tgt_mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "id": "fab47703",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMB_SIZE = 16\n",
    "NHEAD = 8\n",
    "FFN_HID_DIM = 512\n",
    "BATCH_SIZE = 128\n",
    "NUM_ENCODER_LAYERS = 3\n",
    "NUM_DECODER_LAYERS = 3\n",
    "\n",
    "transformer = EEG_Transformer(NUM_ENCODER_LAYERS, NUM_DECODER_LAYERS, EMB_SIZE,\n",
    "                                 NHEAD, FFN_HID_DIM)\n",
    "\n",
    "for p in transformer.parameters():\n",
    "    if p.dim() > 1:\n",
    "        nn.init.xavier_uniform_(p)\n",
    "\n",
    "transformer = transformer.to(DEVICE)\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    transformer.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "id": "b7b46ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_square_subsequent_mask(sz):\n",
    "    mask = (torch.triu(torch.ones((sz, sz), device=DEVICE)) == 1).transpose(0, 1)\n",
    "    mask = mask.float().masked_fill(mask == 0, float(\n",
    "        '-inf')).masked_fill(mask == 1, float(0.0))\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "id": "479a0334",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mask(src, tgt):\n",
    "    src_seq_len = src.shape[1]\n",
    "    tgt_seq_len = tgt.shape[1]\n",
    "\n",
    "    tgt_mask = generate_square_subsequent_mask(tgt_seq_len)\n",
    "    src_mask = torch.zeros((src_seq_len, src_seq_len),\n",
    "                           device=DEVICE).type(torch.bool)\n",
    "\n",
    "    return src_mask, tgt_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "id": "29312a60",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]], device='mps:0')\n",
      "tensor([[0., -inf, -inf,  ..., -inf, -inf, -inf],\n",
      "        [0., 0., -inf,  ..., -inf, -inf, -inf],\n",
      "        [0., 0., 0.,  ..., -inf, -inf, -inf],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., -inf, -inf],\n",
      "        [0., 0., 0.,  ..., 0., 0., -inf],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "for eeg, att in train_dataloader:  \n",
    "    sample_src_mask, sample_tgt_mask = create_mask(eeg, att)\n",
    "    break\n",
    "\n",
    "print(sample_src_mask)\n",
    "print(sample_tgt_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "id": "fe042018",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, optimizer, dataloader):\n",
    "    model.train()\n",
    "    losses = 0\n",
    "    sent_cnt = 0\n",
    "    correct, total = 0, 0\n",
    "    for eeg, att in tqdm(train_dataloader):\n",
    "        eeg = eeg.to(DEVICE)\n",
    "        att = att.to(DEVICE)\n",
    "\n",
    "        att_input = att[:,:-1, :]\n",
    "\n",
    "#         eeg_mask, att_mask = create_mask(eeg, att_input)\n",
    "        \n",
    "        print(\"EEG: \",eeg.shape)\n",
    "        print(\"ATT: \",att_input.shape)\n",
    "#         print(\"EEG MASK: \",eeg_mask.shape)\n",
    "#         print(\"ATT MASK: \",att_mask.shape)\n",
    "\n",
    "        logits = model(eeg,\n",
    "                       att_input)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        tgt_out = tgt[1:, :]\n",
    "        loss = loss_fn(\n",
    "            logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        losses += loss.item()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            sent_cnt += tgt_out.size()[-1]\n",
    "\n",
    "            total += torch.numel(tgt_input)\n",
    "            _, char_pred = torch.max(logits, -1)\n",
    "            correct += (char_pred == tgt_out).sum().item()\n",
    "\n",
    "    return losses / sent_cnt, correct / total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "id": "d194e412",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                                                                                               | 0/2112 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG:  torch.Size([1, 128, 66, 1])\n",
      "ATT:  torch.Size([1, 127, 1])\n",
      "SIZE OF src_emb:  torch.Size([1, 8448, 16])\n",
      "SIZE OF tgt_emb:  torch.Size([1, 127, 16])\n",
      "SIZE OF src_mask:  torch.Size([8448, 8448])\n",
      "SIZE OF tgt_mask:  torch.Size([127, 127])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                               | 0/2112 [00:10<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "MPS backend out of memory (MPS allocated: 13.95 GB, other allocations: 2.13 GB, max allowed: 18.13 GB). Tried to allocate 2.13 GB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[483], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_loss, train_acc \u001b[38;5;241m=\u001b[39m train_epoch(transformer, optimizer, train_dataloader)\n",
      "Cell \u001b[0;32mIn[482], line 19\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(model, optimizer, dataloader)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mATT: \u001b[39m\u001b[38;5;124m\"\u001b[39m,att_input\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m#         print(\"EEG MASK: \",eeg_mask.shape)\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m#         print(\"ATT MASK: \",att_mask.shape)\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m         logits \u001b[38;5;241m=\u001b[39m model(eeg,\n\u001b[1;32m     20\u001b[0m                        att_input)\n\u001b[1;32m     22\u001b[0m         optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     24\u001b[0m         tgt_out \u001b[38;5;241m=\u001b[39m tgt[\u001b[38;5;241m1\u001b[39m:, :]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[477], line 37\u001b[0m, in \u001b[0;36mEEG_Transformer.forward\u001b[0;34m(self, src, trg)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSIZE OF src_mask: \u001b[39m\u001b[38;5;124m\"\u001b[39m, src_mask\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSIZE OF tgt_mask: \u001b[39m\u001b[38;5;124m\"\u001b[39m, tgt_mask\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m---> 37\u001b[0m outs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformer(src_emb, tgt_emb, src_mask, tgt_mask, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outs\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/transformer.py:206\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[0;34m(self, src, tgt, src_mask, tgt_mask, memory_mask, src_key_padding_mask, tgt_key_padding_mask, memory_key_padding_mask, src_is_causal, tgt_is_causal, memory_is_causal)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m src\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39md_model \u001b[38;5;129;01mor\u001b[39;00m tgt\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39md_model:\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe feature number of src and tgt must be equal to d_model\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 206\u001b[0m memory \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(src, mask\u001b[38;5;241m=\u001b[39msrc_mask, src_key_padding_mask\u001b[38;5;241m=\u001b[39msrc_key_padding_mask,\n\u001b[1;32m    207\u001b[0m                       is_causal\u001b[38;5;241m=\u001b[39msrc_is_causal)\n\u001b[1;32m    208\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder(tgt, memory, tgt_mask\u001b[38;5;241m=\u001b[39mtgt_mask, memory_mask\u001b[38;5;241m=\u001b[39mmemory_mask,\n\u001b[1;32m    209\u001b[0m                       tgt_key_padding_mask\u001b[38;5;241m=\u001b[39mtgt_key_padding_mask,\n\u001b[1;32m    210\u001b[0m                       memory_key_padding_mask\u001b[38;5;241m=\u001b[39mmemory_key_padding_mask,\n\u001b[1;32m    211\u001b[0m                       tgt_is_causal\u001b[38;5;241m=\u001b[39mtgt_is_causal, memory_is_causal\u001b[38;5;241m=\u001b[39mmemory_is_causal)\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/transformer.py:391\u001b[0m, in \u001b[0;36mTransformerEncoder.forward\u001b[0;34m(self, src, mask, src_key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m    388\u001b[0m is_causal \u001b[38;5;241m=\u001b[39m _detect_is_causal_mask(mask, is_causal, seq_len)\n\u001b[1;32m    390\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m mod \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m--> 391\u001b[0m     output \u001b[38;5;241m=\u001b[39m mod(output, src_mask\u001b[38;5;241m=\u001b[39mmask, is_causal\u001b[38;5;241m=\u001b[39mis_causal, src_key_padding_mask\u001b[38;5;241m=\u001b[39msrc_key_padding_mask_for_layers)\n\u001b[1;32m    393\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_nested:\n\u001b[1;32m    394\u001b[0m     output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mto_padded_tensor(\u001b[38;5;241m0.\u001b[39m, src\u001b[38;5;241m.\u001b[39msize())\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/transformer.py:714\u001b[0m, in \u001b[0;36mTransformerEncoderLayer.forward\u001b[0;34m(self, src, src_mask, src_key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m    712\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ff_block(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm2(x))\n\u001b[1;32m    713\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 714\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm1(x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sa_block(x, src_mask, src_key_padding_mask, is_causal\u001b[38;5;241m=\u001b[39mis_causal))\n\u001b[1;32m    715\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm2(x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ff_block(x))\n\u001b[1;32m    717\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/transformer.py:722\u001b[0m, in \u001b[0;36mTransformerEncoderLayer._sa_block\u001b[0;34m(self, x, attn_mask, key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m    720\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_sa_block\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor,\n\u001b[1;32m    721\u001b[0m               attn_mask: Optional[Tensor], key_padding_mask: Optional[Tensor], is_causal: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 722\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mself_attn(x, x, x,\n\u001b[1;32m    723\u001b[0m                        attn_mask\u001b[38;5;241m=\u001b[39mattn_mask,\n\u001b[1;32m    724\u001b[0m                        key_padding_mask\u001b[38;5;241m=\u001b[39mkey_padding_mask,\n\u001b[1;32m    725\u001b[0m                        need_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, is_causal\u001b[38;5;241m=\u001b[39mis_causal)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    726\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout1(x)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/activation.py:1241\u001b[0m, in \u001b[0;36mMultiheadAttention.forward\u001b[0;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   1227\u001b[0m     attn_output, attn_output_weights \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mmulti_head_attention_forward(\n\u001b[1;32m   1228\u001b[0m         query, key, value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_dim, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads,\n\u001b[1;32m   1229\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_proj_weight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_proj_bias,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1238\u001b[0m         average_attn_weights\u001b[38;5;241m=\u001b[39maverage_attn_weights,\n\u001b[1;32m   1239\u001b[0m         is_causal\u001b[38;5;241m=\u001b[39mis_causal)\n\u001b[1;32m   1240\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1241\u001b[0m     attn_output, attn_output_weights \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mmulti_head_attention_forward(\n\u001b[1;32m   1242\u001b[0m         query, key, value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_dim, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads,\n\u001b[1;32m   1243\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_proj_weight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_proj_bias,\n\u001b[1;32m   1244\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias_k, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias_v, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_zero_attn,\n\u001b[1;32m   1245\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_proj\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_proj\u001b[38;5;241m.\u001b[39mbias,\n\u001b[1;32m   1246\u001b[0m         training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining,\n\u001b[1;32m   1247\u001b[0m         key_padding_mask\u001b[38;5;241m=\u001b[39mkey_padding_mask,\n\u001b[1;32m   1248\u001b[0m         need_weights\u001b[38;5;241m=\u001b[39mneed_weights,\n\u001b[1;32m   1249\u001b[0m         attn_mask\u001b[38;5;241m=\u001b[39mattn_mask,\n\u001b[1;32m   1250\u001b[0m         average_attn_weights\u001b[38;5;241m=\u001b[39maverage_attn_weights,\n\u001b[1;32m   1251\u001b[0m         is_causal\u001b[38;5;241m=\u001b[39mis_causal)\n\u001b[1;32m   1252\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_first \u001b[38;5;129;01mand\u001b[39;00m is_batched:\n\u001b[1;32m   1253\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m attn_output\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m), attn_output_weights\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/functional.py:5476\u001b[0m, in \u001b[0;36mmulti_head_attention_forward\u001b[0;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   5473\u001b[0m k \u001b[38;5;241m=\u001b[39m k\u001b[38;5;241m.\u001b[39mview(bsz, num_heads, src_len, head_dim)\n\u001b[1;32m   5474\u001b[0m v \u001b[38;5;241m=\u001b[39m v\u001b[38;5;241m.\u001b[39mview(bsz, num_heads, src_len, head_dim)\n\u001b[0;32m-> 5476\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)\n\u001b[1;32m   5477\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m attn_output\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m)\u001b[38;5;241m.\u001b[39mcontiguous()\u001b[38;5;241m.\u001b[39mview(bsz \u001b[38;5;241m*\u001b[39m tgt_len, embed_dim)\n\u001b[1;32m   5479\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m linear(attn_output, out_proj_weight, out_proj_bias)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: MPS backend out of memory (MPS allocated: 13.95 GB, other allocations: 2.13 GB, max allowed: 18.13 GB). Tried to allocate 2.13 GB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure)."
     ]
    }
   ],
   "source": [
    "train_loss, train_acc = train_epoch(transformer, optimizer, train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "3a98073e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader):\n",
    "    model.eval()\n",
    "    losses = 0\n",
    "    sent_cnt = 0\n",
    "    correct, total = 0, 0\n",
    "\n",
    "    for src_batch, tgt_batch in dataloader:\n",
    "        src = src_batch.to(DEVICE)\n",
    "        tgt = tgt_batch.to(DEVICE)\n",
    "\n",
    "        tgt_input = tgt[:-1, :]\n",
    "\n",
    "        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(\n",
    "            src, tgt_input)\n",
    "\n",
    "        logits = model(src, tgt_input, src_mask, tgt_mask,\n",
    "                       src_padding_mask, tgt_padding_mask, src_padding_mask)\n",
    "\n",
    "        tgt_out = tgt[1:, :]\n",
    "        loss = loss_fn(\n",
    "            logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
    "        losses += loss.item()\n",
    "        sent_cnt += tgt_out.size()[-1]\n",
    "\n",
    "        total += torch.numel(tgt_input)\n",
    "        _, char_pred = torch.max(logits, -1)\n",
    "        correct += (char_pred == tgt_out).sum().item()\n",
    "\n",
    "    return losses / sent_cnt, correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "d63ce4ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                  | 0/2112 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 16, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                  | 0/2112 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [64, 128, 8, 1], expected input[1, 0, 128, 1] to have 128 channels, but got 0 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[121], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, NUM_EPOCHS \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m      9\u001b[0m     start_time \u001b[38;5;241m=\u001b[39m timer()\n\u001b[0;32m---> 10\u001b[0m     train_loss, train_acc \u001b[38;5;241m=\u001b[39m train_epoch(\n\u001b[1;32m     11\u001b[0m         transformer, optimizer, train_dataloader)\n\u001b[1;32m     12\u001b[0m     train_losses \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [train_loss]\n\u001b[1;32m     13\u001b[0m     train_accs \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [train_acc]\n",
      "Cell \u001b[0;32mIn[120], line 14\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(model, optimizer, dataloader)\u001b[0m\n\u001b[1;32m     10\u001b[0m att_input \u001b[38;5;241m=\u001b[39m att[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :]\n\u001b[1;32m     12\u001b[0m eeg_mask, att_mask \u001b[38;5;241m=\u001b[39m create_mask(eeg, att)\n\u001b[0;32m---> 14\u001b[0m logits \u001b[38;5;241m=\u001b[39m model(eeg,\n\u001b[1;32m     15\u001b[0m                att_input,\n\u001b[1;32m     16\u001b[0m                eeg_mask,\n\u001b[1;32m     17\u001b[0m                att_mask)\n\u001b[1;32m     19\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     21\u001b[0m tgt_out \u001b[38;5;241m=\u001b[39m tgt[\u001b[38;5;241m1\u001b[39m:, :]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[118], line 31\u001b[0m, in \u001b[0;36mEEG_Transformer.forward\u001b[0;34m(self, src, trg, src_mask, tgt_mask)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     26\u001b[0m             src: Tensor,\n\u001b[1;32m     27\u001b[0m             trg: Tensor,\n\u001b[1;32m     28\u001b[0m             src_mask: Tensor,\n\u001b[1;32m     29\u001b[0m             tgt_mask: Tensor):\n\u001b[1;32m     30\u001b[0m     src_emb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpositional_encoding(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding(src))\n\u001b[0;32m---> 31\u001b[0m     tgt_emb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpositional_encoding(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding(trg))\n\u001b[1;32m     32\u001b[0m     outs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformer(src_emb, tgt_emb, src_mask, tgt_mask, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outs\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[81], line 11\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 11\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1(x))\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;66;03m#x = self.norm(x)\u001b[39;00m\n\u001b[1;32m     13\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(x))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_conv_forward(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    454\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    455\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\u001b[38;5;28minput\u001b[39m, weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    457\u001b[0m                 \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [64, 128, 8, 1], expected input[1, 0, 128, 1] to have 128 channels, but got 0 channels instead"
     ]
    }
   ],
   "source": [
    "from timeit import default_timer as timer\n",
    "NUM_EPOCHS = 20#15\n",
    "train_losses = []\n",
    "train_accs = []\n",
    "val_losses = []\n",
    "val_accs = []\n",
    "\n",
    "for epoch in range(1, NUM_EPOCHS + 1):\n",
    "    start_time = timer()\n",
    "    train_loss, train_acc = train_epoch(\n",
    "        transformer, optimizer, train_dataloader)\n",
    "    train_losses += [train_loss]\n",
    "    train_accs += [train_acc]\n",
    "    end_time = timer()\n",
    "    val_loss, val_acc = evaluate(transformer, val_dataloader)\n",
    "    val_losses += [val_loss]\n",
    "    val_accs += [val_acc]\n",
    "    print((f\"Epoch: {epoch}, Train loss: {train_loss:.3f}, Val loss: {val_loss:.3f}, Train acc.: {train_acc:.3f}, Val acc.: {val_acc:.3f}, Epoch time = {(end_time - start_time):.3f}s\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004c26b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to generate output sequence using greedy algorithm\n",
    "def greedy_decode(model, src, src_mask, max_len, start_symbol):\n",
    "    src = src.to(DEVICE)\n",
    "    src_mask = src_mask.to(DEVICE)\n",
    "\n",
    "    memory = model.encode(src, src_mask)\n",
    "    ys = torch.ones(1, 1).fill_(start_symbol).type(torch.long).to(DEVICE)\n",
    "    #print(ys)\n",
    "    for i in range(max_len-1):\n",
    "        memory = memory.to(DEVICE)\n",
    "        tgt_mask = (generate_square_subsequent_mask(ys.size(0))\n",
    "                    .type(torch.bool)).to(DEVICE)\n",
    "        out = model.decode(ys, memory, tgt_mask)\n",
    "        out = out.transpose(0, 1)\n",
    "        prob = model.generator(out[:, -1])\n",
    "        _, next_word = torch.max(prob, dim=1)\n",
    "        next_word = next_word.item()\n",
    "\n",
    "        ys = torch.cat([ys,\n",
    "                        torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=0)\n",
    "        #print(ys) # Remove the comment to understand the loop\n",
    "        if next_word == EOS_IDX:\n",
    "            break\n",
    "    return ys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca25561",
   "metadata": {},
   "outputs": [],
   "source": [
    "# actual function to translate input sentence into target language\n",
    "def translate(model: torch.nn.Module, src_sentence: str):\n",
    "    model.eval()\n",
    "    src = text2codes([src_sentence], token2idx)[0].view(-1, 1)\n",
    "    num_tokens = src.shape[0]\n",
    "    src_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.bool)\n",
    "    tgt_tokens = greedy_decode(\n",
    "        model, src, src_mask, max_len=num_tokens + 20, start_symbol=BOS_IDX).flatten()\n",
    "    tgt_chars_specials = codes2text([tgt_tokens], idx2token)[0]\n",
    "    tgt_chars = []\n",
    "    for char in tgt_chars_specials:\n",
    "        if char != '<bos>' and char != '<eos>':\n",
    "            tgt_chars += [char]\n",
    "    tgt_chars = ''.join(tgt_chars)\n",
    "    return tgt_chars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86cc00ba",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57c73852",
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg = np.expand_dims(eeg,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6d823eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(66, 4224, 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4512b8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(10))\n",
    "model.add(layers.Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "074e593d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4222</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2111</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2109</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1054</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1052</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">875264</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │    <span style=\"color: #00af00; text-decoration-color: #00af00\">56,016,960</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m4222\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_4 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m2111\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m2109\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_5 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m1054\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_8 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m1052\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m36,928\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m875264\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │    \u001b[38;5;34m56,016,960\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m650\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │            \u001b[38;5;34m22\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_2 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m192\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m650\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m11\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">56,074,229</span> (213.91 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m56,074,229\u001b[0m (213.91 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">56,074,229</span> (213.91 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m56,074,229\u001b[0m (213.91 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e6450a46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2s/step - accuracy: 0.5208 - loss: 7.7712 - val_accuracy: 0.5000 - val_loss: 8.0590\n",
      "Epoch 2/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2s/step - accuracy: 0.4896 - loss: 8.2030 - val_accuracy: 0.5000 - val_loss: 8.0590\n",
      "Epoch 3/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2s/step - accuracy: 0.5312 - loss: 7.6273 - val_accuracy: 0.5000 - val_loss: 8.0590\n",
      "Epoch 4/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2s/step - accuracy: 0.5104 - loss: 7.9151 - val_accuracy: 0.5000 - val_loss: 8.0590\n",
      "Epoch 5/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2s/step - accuracy: 0.4896 - loss: 8.2030 - val_accuracy: 0.5000 - val_loss: 8.0590\n",
      "Epoch 6/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2s/step - accuracy: 0.5104 - loss: 7.9151 - val_accuracy: 0.5000 - val_loss: 8.0590\n",
      "Epoch 7/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2s/step - accuracy: 0.5000 - loss: 8.0590 - val_accuracy: 0.5000 - val_loss: 8.0590\n",
      "Epoch 8/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2s/step - accuracy: 0.4896 - loss: 8.2030 - val_accuracy: 0.5000 - val_loss: 8.0590\n",
      "Epoch 9/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2s/step - accuracy: 0.4792 - loss: 8.3469 - val_accuracy: 0.5000 - val_loss: 8.0590\n",
      "Epoch 10/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2s/step - accuracy: 0.5000 - loss: 8.0590 - val_accuracy: 0.5000 - val_loss: 8.0590\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(eeg[0:60,:,:,:], labels[0:60], epochs=10, \n",
    "                    validation_data=(eeg[61:-1,:,:,:], labels[61:-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60f912b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d4ac43",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8765453b",
   "metadata": {},
   "source": [
    "## TRANSFORMER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602c8006",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5eeb931",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing the Add & Norm Layer\n",
    "class AddNormalization(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(AddNormalization, self).__init__(**kwargs)\n",
    "        self.layer_norm = LayerNormalization()  # Layer normalization layer\n",
    " \n",
    "    def call(self, x, sublayer_x):\n",
    "        # The sublayer input and output need to be of the same shape to be summed\n",
    "        add = x + sublayer_x\n",
    " \n",
    "        # Apply layer normalization to the sum\n",
    "        return self.layer_norm(add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e58e2fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing the Feed-Forward Layer\n",
    "class FeedForward(Layer):\n",
    "    def __init__(self, d_ff, d_model, **kwargs):\n",
    "        super(FeedForward, self).__init__(**kwargs)\n",
    "        self.fully_connected1 = Dense(d_ff)  # First fully connected layer\n",
    "        self.fully_connected2 = Dense(d_model)  # Second fully connected layer\n",
    "        self.activation = ReLU()  # ReLU activation layer\n",
    " \n",
    "    def call(self, x):\n",
    "        # The input is passed into the two fully-connected layers, with a ReLU in between\n",
    "        x_fc1 = self.fully_connected1(x)\n",
    " \n",
    "        return self.fully_connected2(self.activation(x_fc1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4fc5f246",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing the Encoder Layer\n",
    "class EncoderLayer(Layer):\n",
    "    def __init__(self, h, d_k, d_v, d_model, d_ff, rate, **kwargs):\n",
    "        super(EncoderLayer, self).__init__(**kwargs)\n",
    "        self.multihead_attention = MultiHeadAttention(h, d_k, d_v, d_model)\n",
    "        self.dropout1 = Dropout(rate)\n",
    "        self.add_norm1 = AddNormalization()\n",
    "        self.feed_forward = FeedForward(d_ff, d_model)\n",
    "        self.dropout2 = Dropout(rate)\n",
    "        self.add_norm2 = AddNormalization()\n",
    " \n",
    "    def call(self, x, padding_mask, training):\n",
    "        # Multi-head attention layer\n",
    "        multihead_output = self.multihead_attention(x, x, x, padding_mask)\n",
    "        # Expected output shape = (batch_size, sequence_length, d_model)\n",
    " \n",
    "        # Add in a dropout layer\n",
    "        multihead_output = self.dropout1(multihead_output, training=training)\n",
    " \n",
    "        # Followed by an Add & Norm layer\n",
    "        addnorm_output = self.add_norm1(x, multihead_output)\n",
    "        # Expected output shape = (batch_size, sequence_length, d_model)\n",
    " \n",
    "        # Followed by a fully connected layer\n",
    "        feedforward_output = self.feed_forward(addnorm_output)\n",
    "        # Expected output shape = (batch_size, sequence_length, d_model)\n",
    " \n",
    "        # Add in another dropout layer\n",
    "        feedforward_output = self.dropout2(feedforward_output, training=training)\n",
    " \n",
    "        # Followed by another Add & Norm layer\n",
    "        return self.add_norm2(addnorm_output, feedforward_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f838de80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing the Encoder\n",
    "class Encoder(Layer):\n",
    "    def __init__(self, vocab_size, sequence_length, h, d_k, d_v, d_model, d_ff, n, rate, **kwargs):\n",
    "        super(Encoder, self).__init__(**kwargs)\n",
    "        self.pos_encoding = PositionEmbeddingFixedWeights(sequence_length, vocab_size, d_model)\n",
    "        self.dropout = Dropout(rate)\n",
    "        self.encoder_layer = [EncoderLayer(h, d_k, d_v, d_model, d_ff, rate) for _ in range(n)]\n",
    " \n",
    "    def call(self, input_sentence, padding_mask, training):\n",
    "        # Generate the positional encoding\n",
    "        pos_encoding_output = self.pos_encoding(input_sentence)\n",
    "        # Expected output shape = (batch_size, sequence_length, d_model)\n",
    " \n",
    "        # Add in a dropout layer\n",
    "        x = self.dropout(pos_encoding_output, training=training)\n",
    " \n",
    "        # Pass on the positional encoded values to each encoder layer\n",
    "        for i, layer in enumerate(self.encoder_layer):\n",
    "            x = layer(x, padding_mask, training)\n",
    " \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3bec832",
   "metadata": {},
   "source": [
    "## TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "94e16edf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80, 66, 4224)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h = 8  # Number of self-attention heads\n",
    "d_k = 64  # Dimensionality of the linearly projected queries and keys\n",
    "d_v = 64  # Dimensionality of the linearly projected values\n",
    "d_ff = 2048  # Dimensionality of the inner fully connected layer\n",
    "d_model = 512  # Dimensionality of the model sub-layers' outputs\n",
    "n = 6  # Number of layers in the encoder stack\n",
    " \n",
    "batch_size = 64  # Batch size from the training process\n",
    "dropout_rate = 0.1  # Frequency of dropping the input units in the dropout layers\n",
    "\n",
    "enc_vocab_size =  # Vocabulary size for the encoder\n",
    "input_seq_length =   # Maximum length of the input sequence\n",
    " \n",
    "input_seq = random.random((batch_size, input_seq_length))\n",
    "\n",
    "encoder = Encoder(enc_vocab_size, input_seq_length, h, d_k, d_v, d_model, d_ff, n, dropout_rate)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
